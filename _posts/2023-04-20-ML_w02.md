---
layout: post
title: "ML:w02"
categories: [lecture]
---

## Unsupervised Learning을 잘 해서 Supervised Learning을 하는 것이 중요

|학습 종류|방식|설명|
|-------|---|---|
|Supervised Learning (지도학습)|Regression(y값이 Continuous target)<br>Classification(y값이 Discrete target)|정답인 y를 다 알려주고 시작|
|Unsupervised Learning (비지도학습)|어떻게 그게 가능하지?<br>x 자체를 생김새만 보고 분류하는 것이다.<br>Clustering, Outlier detection, Feature extraction(고차원 정보를 저차원으로 변환하여 쉽게 계산)| y를 모른 채 x만 가지고 학습|
|Reinforcement Learning (강화학습)|Robotics control<br>Game, AlphaGo.|로봇이 탐험하며 새로운 데이터를 얻어 반복 학습, 정말 어려운 영역. action이라는 개념이 유일하게 있음|

현대에는 세 가지 기술이 융합

UL을 기반으로.

## Linear model로 해결이 안 되는 Nonelinear model은?

선을 여러 개 긋자. &rarr; Neural Network 탄생

## 하나의 뉴런은

Input 값에 Weight(가중치)를 곱한 모든 값을 합하고 이를 Step function을 거쳐 결과 값을 도출

이러한 하나의 뉴런을 여러 개 연결해 놓은 것이 **:star2: Deep Neural Network (DNN)**

축약형은 Deep Learning

2층짜리는 Neural Network

##  Step function

- Sigmoid
- ReLu
- Soft ReLu

## 사칙연산일 뿐이므로 수학적으로는 복잡하지 않다.

각 x의 결과 = 시그모이드(시그마(가중치 * x값))

최종 출력 = 시그마(각 x의 결과)

## Back propagation

적절한 가중치 값을 찾기 위해 역전파 알고리즘 사용

## 어떻게 설계하느냐에 따라 여러 개의 대상을 한 번에 학습 가능

## :star2: Convolution Neural Network (CNN)

> 데이터를 일렬로 나열하는 것이 최선일까?

이미지가 갖는 특성을 잘 필터링해 보자!

필터를 움직이면서 훑어보며 곱할 가중치 값을 찾아내는 것이 목적

$32*32*3$ 의 이미지를 $5*5*3$ 크기의 필터 6개로 필터링을 하게 되면 필터의 크기를 제외한 $28*28*6$ 의 새로운 이미지로 축소, 변환이 된다.

$28*28*6$ 에서 6인 이유는 필터가 6개이기 때문에 6장의 $28*28*1$ 이미지가 나오기 때문이다.

## Convolution layer: pooling

이미지의 크기를 줄이는 과정. 네 칸으로 나누어 가장 큰 값을 대표하도록 하거나, 평균 값을 대표하도록 하여 크기를 $1/4$ 배 줄임.

## :star2: Recurrent Neural Network (RNN)

ChatGPT도 RNN 기반

데이터가 시간 순서대로 되어 있음

학습 파라미터의 개수가 압도적으로 많음

---

## Training data & Test data

Training 단계에서 Test 데이터를 사용하면 절대 안돼!

## Dimensionality reduction

= feature extraction

높은 차원의 데이터를 분리하여 낮은 차원으로 프로젝션 시킴. 학습이 더 잘 될 수 있도록 도와줌

## Reinforcement Learning - 알파고

환경과 동작을 마주하여 더 긍정적인 점수를 많이 받을 수 있도록 스스로 학습하여 미래의 점수를 최대로 만들 수 있는 동작을 선택

- Supervised Learning과 다른 점
SL은 답을 다 알려주는 것.
Reinforcement learning은 Training data가 실세계에서 실시간으로 얻어지고, 맞는지 틀린지 아무도 알려주지 않는다.
바둑 같은 고정되지 않은 환경은 강화학습이 정말 어려움

## 강화학습을 나누는 방식

> 현재 state에 대해서 다음 state는 어떨까를 예측 (악셀을 밟고 핸들을 돌리면? 자동차의 다음 위치)

1. Model-based RL
2. Model-free RL (state 없이 바로 Q function을 학습)

Model-free는 Model이 아닌 다른 부분에서 학습을 더 진행해야 하므로 결과적으로 더 많은 학습을 필요

## End-to-end Deep learning

기존의 딥러닝 단계에서 두 단계를 생략

### 모든 분야에 다 Deep Neural Network 구조 하나가 강화학습까지도 풀게 할 수 있다는 것이 end-to-end learning의 개념.